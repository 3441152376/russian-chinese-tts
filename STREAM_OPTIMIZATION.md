# 流式接口性能优化说明

## 问题描述

前端使用流式接口 `/api/v1/tts/generate-stream` 获取已缓存的音频时，耗时仍然较长（约 2503ms），即使音频文件已经生成并缓存。

## 优化方案

### 1. 小文件一次性读取优化

**问题**：对于小文件（如 22KB），使用分块读取（8KB块）会产生多次 I/O 操作和异步上下文切换，影响性能。

**优化**：
- 对于小于 100KB 的文件，使用一次性读取
- 对于大于 100KB 的文件，继续使用分块读取以节省内存

**代码变更**：
```python
if file_size < 100 * 1024:  # 小于100KB
    # 小文件：一次性读取
    async with aiofiles.open(file_path, 'rb') as f:
        audio_data = await f.read()
    async def generate():
        yield audio_data
else:
    # 大文件：分块读取
    async def generate():
        async with aiofiles.open(file_path, 'rb') as f:
            while True:
                chunk = await f.read(8192)
                if not chunk:
                    break
                yield chunk
```

### 2. 性能追踪日志

添加详细的性能追踪日志，帮助诊断性能瓶颈：

- `[性能追踪] 收到流式 TTS 请求` - 请求开始时间
- `[性能追踪] TTS服务调用耗时` - 服务层耗时（包括缓存检查）
- `[性能追踪] 缓存命中` - 缓存命中情况
- `[性能追踪] 文件读取耗时` - 文件读取耗时
- `[性能追踪] 流式接口总耗时` - 总耗时统计

### 3. 缓存命中状态返回

在响应头中添加 `X-Cache-Hit` 头，前端可以判断是否命中缓存：

```python
headers={
    "X-Cache-Hit": "true" if is_cached else "false"
}
```

## 预期效果

### 优化前
- 小文件（22KB）分块读取：多次 I/O 操作
- 缓存命中后总耗时：~2500ms

### 优化后
- 小文件（22KB）一次性读取：单次 I/O 操作
- 缓存命中后总耗时：预计 < 100ms（文件读取）+ 网络传输时间

## 性能监控

优化后，日志中会显示详细的性能数据：

```
[性能追踪] 收到流式 TTS 请求 - 文本长度: 50
[性能追踪] 缓存命中 - cache_key: xxx
[性能追踪] TTS服务调用耗时: 5.23ms, 缓存命中: True
[性能追踪] 音频文件大小: 22.08KB
[性能追踪] 文件读取耗时（一次性）: 2.15ms
[性能追踪] 流式接口总耗时: 15.67ms, 缓存: True, 文件大小: 22.08KB
```

## 注意事项

1. **内存使用**：小文件一次性读取会增加内存使用，但 100KB 以下文件的内存占用可接受
2. **大文件处理**：大于 100KB 的文件仍使用分块读取，避免内存压力
3. **网络传输**：优化主要减少服务器端处理时间，网络传输时间取决于网络状况

## 后续优化建议

1. **使用同步文件读取**：对于小文件，可以考虑使用同步的 `open()` 和 `read()`，避免异步开销
2. **HTTP 缓存头**：添加适当的 HTTP 缓存头（如 `Cache-Control`），让浏览器缓存响应
3. **CDN 加速**：如果可能，将音频文件放在 CDN 上，进一步减少传输时间

